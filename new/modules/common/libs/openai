#!/usr/bin/env bash

# Call OpenAI's /completions endpoint to get a response to a prompt
completion() {
  local query="$1"
  local temperature=${2:-0.7}
  local escapedQuery=$(echo "$1" | jq --slurp --raw-input '@json')

  response=$(curl -s https://api.openai.com/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "OpenAI-Organization: $OPENAI_ORG_ID" \
    -d '{
      "model": "gpt-3.5-turbo",
      "messages": [
        {"role": "user", "content": '"$escapedQuery"'}
      ],
      "temperature": '"$temperature"',
    }'
   )

  answer=$(echo "$response" \
    |  jq --raw-output '.choices[0].message.content' 
  )

  if [ -n "$answer" ]; then
    echo "$answer"
    return 0
  fi

  return 1
}

# Call OpenAI's /completions endpoint to get a response to a predefined 
# sumarization prompt.
sumarize() {
  local longText="$1"

  completion "Summarize the following text in 3-10 words. Use present tense and dont include articles and conjunctions.\nText to sumarize:\n$longText"
}

# Save the prompt and answer to a file in the $OPENAI_COMPLETION_HOME folder.
# Persist for later fzf retrieval.
saveCompletion() {
  local part="$1" # "prompt" or "answer"
  local prompt="$2"
  local completionId="$3"
  local folder="$OPENAI_COMPLETION_HOME/$completionId"

  if [ ! -d "$folder" ]; then
    mkdir -p "$folder"
  fi

  echo -e "$prompt\n" > "$folder/$part.md"
}
